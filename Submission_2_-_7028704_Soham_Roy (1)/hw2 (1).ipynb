{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FKZDMi_5iKCA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "from matplotlib.colors import LightSource\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'svg'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-A0EQP5iN5L",
        "outputId": "9fd45743-ca63-49df-f975-eeee9e93d22a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 76510044.58it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 4330605.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 110558739.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 14487094.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# download MNIST training and testing datasets, then prepare corresponding dataloaders (batch size = 100)\n",
        "mnist_train = datasets.MNIST(\"./data\", train=True, download=True, transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(\"./data\", train=False, download=True, transform=transforms.ToTensor())\n",
        "train_loader = DataLoader(mnist_train, batch_size = 100, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size = 100, shuffle=False)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "PjUrtvq_iUbQ"
      },
      "outputs": [],
      "source": [
        "# initialize the CNN architecture with 4 convolutional layers and 2 MLP layers for standard training\n",
        "torch.manual_seed(0)\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "model_cnn = nn.Sequential(nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
        "                          nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                          nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "                          nn.Conv2d(64, 64, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                          Flatten(),\n",
        "                          nn.Linear(7*7*64, 100), nn.ReLU(),\n",
        "                          nn.Linear(100, 10)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "M_cv5SjtiWZE"
      },
      "outputs": [],
      "source": [
        "#### Your task: complete the following function\n",
        "def pgd(model, X, y, epsilon=0.1, alpha=0.02, num_iter=10, randomize=False):\n",
        "    \"\"\" Construct PGD adversarial examples for the example (X,y)\"\"\"\n",
        "\n",
        "    # delta stores the generated perturbation and updates its value iteratively\n",
        "    delta = torch.zeros_like(X,requires_grad=True).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    #optimizer = torch.optim.SGD([delta], lr= alpha)\n",
        "    for t in range(num_iter):\n",
        "        #optimizer.zero_grad()\n",
        "        pred = model((X + delta).to(device))\n",
        "        output =  nn.CrossEntropyLoss()(pred.to(device),torch.tensor(y).to(device))\n",
        "        output.backward()\n",
        "        delta.data = delta.data + delta.grad.detach()\n",
        "        delta.data = delta.data.clamp(-epsilon,epsilon)\n",
        "        delta.grad.zero_()\n",
        "\n",
        "\n",
        "    return delta\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "N6yvOm8ciZUL"
      },
      "outputs": [],
      "source": [
        "#### Your task: complete the following functions\n",
        "def epoch(loader, model, opt=None):\n",
        "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
        "    loss = 0\n",
        "    if(opt!= None):\n",
        "      for (i,j) in (loader):\n",
        "            opt.zero_grad()\n",
        "            pred = model(i.to(device))\n",
        "            loss =  nn.CrossEntropyLoss()(pred,torch.LongTensor(j).to(device))\n",
        "            # Backward pass to compute the gradient\n",
        "            with(torch.enable_grad()):\n",
        "              loss.backward()\n",
        "            # Clip the gradient to the range [-epsilon, epsilon]\n",
        "            opt.step()\n",
        "\n",
        "    errors = 0\n",
        "    loss = 0\n",
        "    for (i,j) in (loader):\n",
        "      pred = model(i.to(device))\n",
        "      loss +=  nn.CrossEntropyLoss()(pred,torch.tensor(j).to(device)).item()\n",
        "      predictions = torch.argmax(pred, dim = 1)  # Assuming binary classification\n",
        "      errors += (predictions != j.to(device)).sum().item()\n",
        "    return  errors/len(loader.dataset)*100 , loss\n",
        "\n",
        "\n",
        "def epoch_adv(loader, model, attack, opt=None, **kwargs):\n",
        "    \"\"\"Adversarial training/evaluation epoch over the dataset\"\"\"\n",
        "    loss = 0\n",
        "    errors = 0\n",
        "    tot_l = 0\n",
        "    for (i,j) in (loader):\n",
        "            delta = pgd(model, i.to(device) ,torch.tensor(j).to(device), num_iter = 10)\n",
        "            pred = model(i.to(device) + delta)\n",
        "            loss =  nn.CrossEntropyLoss()(pred,torch.tensor(j).to(device))\n",
        "            if (opt != None):\n",
        "                opt.zero_grad()\n",
        "                loss.backward()\n",
        "                opt.step()\n",
        "            tot_l += loss\n",
        "            errors += (torch.argmax(pred, dim = 1) != j.to(device)).sum().item()\n",
        "\n",
        "    return errors/len(loader.dataset)*100  , tot_l\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "HDwITEWRiaxv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "14091e78-8cc2-4ab1-c19e-31c1f869f189"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-adc50d01d4cd>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss +=  nn.CrossEntropyLoss()(pred,torch.tensor(j).to(device)).item()\n",
            "<ipython-input-23-adc50d01d4cd>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  delta = pgd(model, i.to(device) ,torch.tensor(j).to(device), num_iter = 10)\n",
            "<ipython-input-7-32173fd2e450>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  output =  nn.CrossEntropyLoss()(pred.to(device),torch.tensor(y).to(device))\n",
            "<ipython-input-23-adc50d01d4cd>:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss =  nn.CrossEntropyLoss()(pred,torch.tensor(j).to(device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.170000\t3.070000\t4.930000\n",
            "1.798333\t2.290000\t4.150000\n",
            "1.163333\t1.540000\t3.200000\n",
            "1.035000\t1.630000\t3.520000\n",
            "0.756667\t1.360000\t2.870000\n"
          ]
        }
      ],
      "source": [
        "# specify the optimizer as SGD\n",
        "opt = optim.SGD(model_cnn.parameters(), lr=1e-1)\n",
        "\n",
        "# standard training\n",
        "for t in range(5):\n",
        "    train_err, train_loss = epoch(train_loader, model_cnn, opt)\n",
        "    test_err, test_loss = epoch(test_loader, model_cnn)\n",
        "    adv_err, adv_loss = epoch_adv(test_loader, model_cnn, pgd)\n",
        "\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err, adv_err)), sep=\"\\t\")\n",
        "\n",
        "# save the standard trained model for further evaluation\n",
        "torch.save(model_cnn.state_dict(), \"model_cnn.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "4Dht-vSxlloO"
      },
      "outputs": [],
      "source": [
        "# use the same CNN architecture for robust training\n",
        "model_cnn_robust = nn.Sequential(nn.Conv2d(1, 32, 3, padding=1), nn.ReLU(),\n",
        "                                 nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                                 nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "                                 nn.Conv2d(64, 64, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                                 Flatten(),\n",
        "                                 nn.Linear(7*7*64, 100), nn.ReLU(),\n",
        "                                 nn.Linear(100, 10)).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KKsmaBalooX",
        "outputId": "73219435-aad1-4e1f-e92a-f9b8e3cb5b3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-adc50d01d4cd>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  delta = pgd(model, i.to(device) ,torch.tensor(j).to(device), num_iter = 10)\n",
            "<ipython-input-7-32173fd2e450>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  output =  nn.CrossEntropyLoss()(pred.to(device),torch.tensor(y).to(device))\n",
            "<ipython-input-23-adc50d01d4cd>:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss =  nn.CrossEntropyLoss()(pred,torch.tensor(j).to(device))\n",
            "<ipython-input-23-adc50d01d4cd>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss +=  nn.CrossEntropyLoss()(pred,torch.tensor(j).to(device)).item()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "17.101667\t2.410000\t3.320000\n",
            "2.976667\t1.710000\t2.460000\n",
            "2.221667\t1.360000\t2.160000\n",
            "1.690000\t1.180000\t1.890000\n",
            "1.401667\t1.190000\t1.810000\n"
          ]
        }
      ],
      "source": [
        "# specify the optimizer as SGD\n",
        "opt = optim.SGD(model_cnn_robust.parameters(), lr=1e-1)\n",
        "\n",
        "# PGD-based adversarial training\n",
        "for t in range(5):\n",
        "    train_err, train_loss = epoch_adv(train_loader, model_cnn_robust, pgd, opt)\n",
        "    test_err, test_loss = epoch(test_loader, model_cnn_robust)\n",
        "    adv_err, adv_loss = epoch_adv(test_loader, model_cnn_robust, pgd)\n",
        "\n",
        "    print(*(\"{:.6f}\".format(i) for i in (train_err, test_err, adv_err)), sep=\"\\t\")\n",
        "\n",
        "# save the standard trained model for further evaluation\n",
        "torch.save(model_cnn_robust.state_dict(), \"model_cnn_robust.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "fT5MZujiN9Da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3fe1e77-c07f-40ea-a296-43e766c58dd4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "# load the standard trained and adversarially trained models\n",
        "model_cnn.load_state_dict(torch.load(\"model_cnn.pt\"))\n",
        "model_cnn_robust.load_state_dict(torch.load(\"model_cnn_robust.pt\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "f48ELj_UN-uI"
      },
      "outputs": [],
      "source": [
        "def fgsm(model, X, y, epsilon=0.1):\n",
        "    \"\"\" Construct FGSM adversarial examples for the example (X,y)\"\"\"\n",
        "    delta = torch.zeros_like(X, requires_grad=True)\n",
        "    loss = nn.CrossEntropyLoss()(model(X + delta), y)\n",
        "    loss.backward()\n",
        "    return epsilon * delta.grad.detach().sign()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ecDX3ziXPibw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9682c24-51c6-4211-cf81-fe95f9d41a43"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-adc50d01d4cd>:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss +=  nn.CrossEntropyLoss()(pred,torch.tensor(j).to(device)).item()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clean: 1.3600 1.1900\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-23-adc50d01d4cd>:32: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  delta = pgd(model, i.to(device) ,torch.tensor(j).to(device), num_iter = 10)\n",
            "<ipython-input-7-32173fd2e450>:12: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  output =  nn.CrossEntropyLoss()(pred.to(device),torch.tensor(y).to(device))\n",
            "<ipython-input-23-adc50d01d4cd>:34: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss =  nn.CrossEntropyLoss()(pred,torch.tensor(j).to(device))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FGSM:  2.8700 1.8100\n",
            "PGD (10 iter): 2.8700 1.8100\n"
          ]
        }
      ],
      "source": [
        "# clean performance (no attack)\n",
        "print(\"clean:\", \"{:.4f}\".format(epoch(test_loader, model_cnn)[0]),\n",
        "      \"{:.4f}\".format(epoch(test_loader, model_cnn_robust)[0]))\n",
        "\n",
        "# evaluate both models using FGSM attack\n",
        "print(\"FGSM: \", \"{:.4f}\".format(epoch_adv(test_loader, model_cnn, fgsm)[0]),\n",
        "      \"{:.4f}\".format(epoch_adv(test_loader, model_cnn_robust, fgsm)[0]))\n",
        "\n",
        "# evaluate both models using PGD attack\n",
        "print(\"PGD (10 iter):\", \"{:.4f}\".format(epoch_adv(test_loader, model_cnn, pgd, num_iter=10)[0]),\n",
        "      \"{:.4f}\".format(epoch_adv(test_loader, model_cnn_robust, pgd, num_iter=10)[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-EfxdKahQL3v"
      },
      "outputs": [],
      "source": [
        "#### Your task (bonus): develop an attack method to achieve an attack success rate as high as possible. You can modify the following function if needed.\n",
        "\n",
        "# You can try out some of the attack methods introduced in Lectures 3-4 or develop your unique creative attack.\n",
        "# In principle, the performance of your attack should be better than FGSM or PGD, 10 iter;\n",
        "# The higher attack success rates you can achieve, the higher credits you may receive.\n",
        "\n",
        "def my_attack(model, X, y, epsilon=0.1):\n",
        "  \"\"\" Construct adversarial examples for the example (X,y)\"\"\"\n",
        "\n",
        "  return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aQVHww4GRwn6"
      },
      "outputs": [],
      "source": [
        "print(\"My Attack: \", \"{:.4f}\".format(epoch_adv(test_loader, model_cnn, my_attack)[0]),\n",
        "      \"{:.4f}\".format(epoch_adv(test_loader, model_cnn_robust, my_attack)[0]))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}