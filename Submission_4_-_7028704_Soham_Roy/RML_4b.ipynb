{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "For example, let's consider the MNIST dataset and select only 0s and 8s to train a classifier."
      ],
      "metadata": {
        "id": "nxHVpHSqjHbL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7vKwjyK7Vd1e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1eaefcd-625b-4312-8f45-1ed9f406d8f4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m778.1/778.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for ectutorial (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "! pip install git+https://github.com/airi-industrial-ai/ec23-tutorial -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from matplotlib import pyplot as plt\n",
        "from ectutorial.mnist_utils import *\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import random\n"
      ],
      "metadata": {
        "id": "z9rjqQT3VpVi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#Defining a few functions as the images are in a 0-1 scale instead of 0-255 scale\n",
        "def weighted_grayscale(x, color_index=0):\n",
        "    weights = [0.3, 0.59, 0.11]\n",
        "    return x  * weights[color_index]\n",
        "def gen_weighted_grayscale(image):\n",
        "    imgs = [image ]\n",
        "    for c in range(3):\n",
        "        imgs.append(weighted_grayscale(image, c))\n",
        "    cimgs = []\n",
        "    for img in imgs:\n",
        "        gs, _, _, _ = gen_colored(img)\n",
        "        cimgs.append(gs)\n",
        "    return tuple(cimgs)"
      ],
      "metadata": {
        "id": "fzldzlulF8VJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# download MNIST training and testing datasets, then prepare corresponding dataloaders (batch size = 100)\n",
        "mnist_train = datasets.MNIST(\"./data\", train=True, download=True,  transform=transforms.ToTensor())\n",
        "mnist_test = datasets.MNIST(\"./data\", train=False, download=True,  transform=transforms.ToTensor())\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size = 1, shuffle=True)\n",
        "test_loader = DataLoader(mnist_test, batch_size = 1, shuffle=False)\n"
      ],
      "metadata": {
        "id": "bwxwMT6QF8Xn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec897ef9-2d2c-41e7-d69b-1fe642a3f357"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 112797857.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 105243869.53it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 34153056.08it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 20396711.74it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task1"
      ],
      "metadata": {
        "id": "PX4FZyAH9U3D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''\n",
        "    Creating the OOD data class loaders for the three types as mentioned in task 1\n",
        "\n",
        "'''\n",
        "\n",
        "def create_custom_dataloader():\n",
        "  rr = torchvision.transforms.RandomResizedCrop((28, 28))\n",
        "  data_color = []\n",
        "  data_gs_ = []\n",
        "  data_rotate = []\n",
        "  label = []\n",
        "  test_loader = DataLoader(mnist_test, batch_size = 1, shuffle=False)\n",
        "  for i , (x,label_) in enumerate(test_loader):\n",
        "    x = x.squeeze()\n",
        "    data_rotate.append(np.concatenate([rr(x.unsqueeze(0))] * 3, axis=0))\n",
        "    data_color.append(gen_colored(x)[random.randint(1, 3)].transpose(2,0,1))\n",
        "    data_gs_.append(gen_weighted_grayscale(x)[random.randint(1, 3)].transpose(2,0,1))\n",
        "    label.append(label_)\n",
        "\n",
        "\n",
        "  data_colored = [i for i in zip(data_color, label)]\n",
        "  data_gs = [i for i in zip(data_gs_, label)]\n",
        "  data_rotated = [i for i in zip(data_rotate, label)]\n",
        "\n",
        "  data_color_loader = DataLoader(data_colored, batch_size = 32, shuffle=False)\n",
        "  data_gs_loader = DataLoader(data_gs, batch_size = 32, shuffle=False)\n",
        "  data_rotated_loader = DataLoader(data_rotated, batch_size = 32, shuffle=False)\n",
        "\n",
        "  return data_color_loader,data_gs_loader,data_rotated_loader\n",
        "\n"
      ],
      "metadata": {
        "id": "GXldTeFBF8ag"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 2"
      ],
      "metadata": {
        "id": "EECnYbgS9YAN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def epoch(loader, model, opt=None, augmix_augment_ = False):\n",
        "    \"\"\"Standard training/evaluation epoch over the dataset\"\"\"\n",
        "    loss = 0\n",
        "    if(opt!= None):\n",
        "      model.train()\n",
        "      for (i,j) in (loader):\n",
        "            if(augmix_augment_):\n",
        "              i = augmix_augment(i)\n",
        "            j = j.squeeze()\n",
        "            opt.zero_grad()\n",
        "            pred = model(i.to(device))\n",
        "            loss =  nn.CrossEntropyLoss()(pred,torch.LongTensor(j).to(device))\n",
        "            # Backward pass to compute the gradient\n",
        "            with(torch.enable_grad()):\n",
        "              loss.backward()\n",
        "            # Clip the gradient to the range [-epsilon, epsilon]\n",
        "            opt.step()\n",
        "\n",
        "    accuracy = 0\n",
        "    loss = 0\n",
        "    model.eval()\n",
        "    for (i,j) in (loader):\n",
        "      if(augmix_augment_):\n",
        "          # Here the augmix_augment is used to fix the channels to 3 and not do any augmentation on test data as the name might suggest\n",
        "          i = augmix_augment(i, doaug =  False)\n",
        "      j = j.squeeze()\n",
        "      pred = model(i.to(device))\n",
        "      loss +=  nn.CrossEntropyLoss()(pred,torch.tensor(j).to(device)).item()\n",
        "      predictions = torch.argmax(pred, dim = 1)  # Assuming binary classification\n",
        "      accuracy += (predictions == j.to(device)).sum().item()\n",
        "    return  accuracy/len(loader.dataset)*100 , loss\n"
      ],
      "metadata": {
        "id": "ofP7U3YMTVVC"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Utility fn to create the dataloaders for Task 2 (increasing channels from 1 --> 3)\n",
        "modified_images = []\n",
        "labels = []\n",
        "\n",
        "# Apply the channel concatenation transformation to all images\n",
        "for image, label in mnist_train:\n",
        "    # Convert to NumPy array and concatenate along the channel dimension\n",
        "    image_rgb = np.concatenate([image.numpy()] * 3, axis=0)\n",
        "\n",
        "    # Append the modified image and label to the new lists\n",
        "    modified_images.append(image_rgb)\n",
        "    labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "modified_images = np.array(modified_images)\n",
        "mnist_train_3c = [i for i in zip(modified_images, labels)]\n",
        "train_loader = DataLoader(mnist_train_3c, batch_size = 32, shuffle=True)\n",
        "\n",
        "\n",
        "modified_images = []\n",
        "labels = []\n",
        "\n",
        "# Apply the channel concatenation transformation to all images\n",
        "for image, label in mnist_test:\n",
        "    # Convert to NumPy array and concatenate along the channel dimension\n",
        "    image_rgb = np.concatenate([image.numpy()] * 3, axis=0)\n",
        "\n",
        "    # Append the modified image and label to the new lists\n",
        "    modified_images.append(image_rgb)\n",
        "    labels.append(label)\n",
        "\n",
        "# Convert the lists to NumPy arrays\n",
        "modified_images = np.array(modified_images)\n",
        "mnist_test_3c = [i for i in zip(modified_images, labels)]\n",
        "test_loader = DataLoader(mnist_test_3c, batch_size = 32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "IUY0VTtN6C_U"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n",
        "model_cnn = nn.Sequential(nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n",
        "                          nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                          nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "                          nn.Conv2d(64, 64, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                          Flatten(),\n",
        "                          nn.Linear(7*7*64, 100), nn.ReLU(),\n",
        "                          nn.Linear(100, 10)).to(device)"
      ],
      "metadata": {
        "id": "AmbpaJ-iTVSi"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt = optim.SGD(model_cnn.parameters(), lr=1e-1)\n",
        "\n",
        "accuracyC=[]\n",
        "accuracyG=[]\n",
        "accuracyR=[]\n",
        "\n",
        "\n",
        "for t in range(2): # training until 2 epochs only as it is time taking and getting over 99 percent accuracy in 2 epochs itself\n",
        "      acc, train_loss = epoch(train_loader, model_cnn, opt)\n",
        "print(f\"Train accuracy{acc}\" )\n",
        "acc, test_loss = epoch(test_loader, model_cnn)\n",
        "print(f\" Test accuracy{acc}\" )\n",
        "# standard training\n",
        "for times in range(3):\n",
        "  data_color_loader,data_gs_loader,data_rotated_loader = create_custom_dataloader()\n",
        "  acc, test_loss = epoch(data_color_loader, model_cnn)\n",
        "  accuracyC.append(acc)\n",
        "  acc, test_loss = epoch(data_gs_loader, model_cnn)\n",
        "  accuracyG.append(acc)\n",
        "  acc, test_loss = epoch(data_rotated_loader, model_cnn)\n",
        "  accuracyR.append(acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xaFtIW0ITVXo",
        "outputId": "94703480-b978-4998-f21c-61598b4f8d86"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-3659490b9b0f>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss +=  nn.CrossEntropyLoss()(pred,torch.tensor(j).to(device)).item()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy99.01666666666667\n",
            " Test accuracy98.72999999999999\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\n\\nColored_MNIST mean Test accuracy {np.array(accuracyC).mean():.2f} standard deviation {np.array(accuracyC).std():.2f} \" )\n",
        "print(f\"Grayscale_MNIST Test accuracy {np.array(accuracyG).mean():.2f} standard deviation {np.array(accuracyG).std():.2f}\" )\n",
        "print(f\"Rotated_MNIST Test accuracy {np.array(accuracyR).mean():.2f} standard deviation {np.array(accuracyR).std():.2f}\" )\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ni1o6ztwwI3M",
        "outputId": "bdd72d5e-2914-466e-d8ec-83f85bc62179"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Colored_MNIST mean Test accuracy 98.60 standard deviation 0.04 \n",
            "Grayscale_MNIST Test accuracy 98.43 standard deviation 0.05\n",
            "Rotated_MNIST Test accuracy 45.71 standard deviation 0.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Task 4"
      ],
      "metadata": {
        "id": "-PWPU8yKCQaB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(0)\n",
        "\n",
        "class Flatten(nn.Module):\n",
        "    def forward(self, x):\n",
        "        return x.view(x.shape[0], -1)\n",
        "\n"
      ],
      "metadata": {
        "id": "Vof-Gh-l__yQ"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "var = [\"motion_blur\" , \"zigzag\" , \"fog\"]\n",
        "for type_ in var:\n",
        "  model_cnn_aug = nn.Sequential(nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(),\n",
        "                          nn.Conv2d(32, 32, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                          nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(),\n",
        "                          nn.Conv2d(64, 64, 3, padding=1, stride=2), nn.ReLU(),\n",
        "                          Flatten(),\n",
        "                          nn.Linear(7*7*64, 100), nn.ReLU(),\n",
        "                          nn.Linear(100, 10)).to(device)\n",
        "  opt = optim.SGD(model_cnn_aug.parameters(), lr=1e-1)\n",
        "\n",
        "\n",
        "  print(f\"-----------------{type_}-----------------\")\n",
        "  loaded_array_test = np.load(f'./drive/MyDrive/{type_}/test_images.npy')\n",
        "  loaded_array_lab_test = np.load(f'./drive/MyDrive/{type_}/test_labels.npy')\n",
        "\n",
        "  loaded_array_train = np.load(f'./drive/MyDrive/{type_}/train_images.npy')\n",
        "  loaded_array_lab_train = np.load(f'./drive/MyDrive/{type_}/train_labels.npy')\n",
        "\n",
        "  mnist_train_c = [((i / 255.) ,j) for i,j in zip(loaded_array_train, loaded_array_lab_train)]\n",
        "  mnist_test_c = [((i / 255.) ,j) for i,j in zip(loaded_array_test, loaded_array_lab_test)]\n",
        "\n",
        "  train_loader = DataLoader(mnist_train_c, batch_size = 32, shuffle=True)\n",
        "  test_loader = DataLoader(mnist_test_c, batch_size = 32, shuffle=False)\n",
        "\n",
        "\n",
        "  # standard training\n",
        "  for t in range(2):\n",
        "      acc, train_loss = epoch(train_loader, model_cnn_aug, opt , augmix_augment_ = True)\n",
        "  print(f\"Train accuracy{acc}  Train loss : {train_loss}\" )\n",
        "\n",
        "  # NOTE :-  Here the augmix_augment is used to fix the channels to 3 and not do any augmentation on test data as the name might suggest\n",
        "\n",
        "  acc, test_loss = epoch(test_loader, model_cnn_aug , augmix_augment_= True)\n",
        "  print(f\"MNIST-C data trained model Test accuracy{acc}  Test loss : {test_loss}\" )\n",
        "\n",
        "  acc, test_loss = epoch(test_loader, model_cnn , augmix_augment_= True)\n",
        "  print(\"Vanilla model Test accuracy\" , acc, test_loss)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xEiXdUgO9UH0",
        "outputId": "35bc9e0a-9358-4ebc-b9ca-fe4b12a8e2ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------motion_blur-----------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-66-ae1ebb6c045f>:28: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  loss +=  nn.CrossEntropyLoss()(pred,torch.tensor(j).to(device)).item()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train accuracy98.39333333333333  Train loss : 96.79468112639734\n",
            "MNIST-C data trained model Test accuracy98.16  Test loss : 16.92746583907865\n",
            "Vanilla model Test accuracy 97.11 28.42546249111183\n",
            "-----------------zigzag-----------------\n",
            "Train accuracy98.235  Train loss : 100.63171849783976\n",
            "MNIST-C data trained model Test accuracy97.64  Test loss : 21.353138562757522\n",
            "Vanilla model Test accuracy 91.99000000000001 88.41492238239152\n",
            "-----------------fog-----------------\n",
            "Train accuracy98.48166666666667  Train loss : 95.63834621245041\n",
            "MNIST-C data trained model Test accuracy98.07000000000001  Test loss : 17.765403081662953\n",
            "Vanilla model Test accuracy 86.61 151.55270560085773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Utilities for AugMix function"
      ],
      "metadata": {
        "id": "dQa45Upm8BV3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2019 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Reference implementation of AugMix's data augmentation method in numpy.\"\"\"\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "# CIFAR-10 constants\n",
        "MEAN = [0.4914, 0.4822, 0.4465]\n",
        "STD = [0.2023, 0.1994, 0.2010]\n",
        "\n",
        "\n",
        "def normalize(image):\n",
        "  \"\"\"Normalize input image channel-wise to zero mean and unit variance.\"\"\"\n",
        "  image = image.transpose(2, 0, 1)  # Switch to channel-first\n",
        "  mean, std = np.array(MEAN), np.array(STD)\n",
        "  image = (image - mean[:, None, None]) / std[:, None, None]\n",
        "  return image.transpose(1, 2, 0)\n",
        "\n",
        "\n",
        "def apply_op(image, op, severity):\n",
        "  image = np.clip(image * 255., 0, 255).astype(np.uint8)\n",
        "  image = image.squeeze()\n",
        "  pil_img = Image.fromarray(image)  # Convert to PIL.Image\n",
        "  pil_img = op(pil_img, severity)\n",
        "  return np.asarray(pil_img) / 255.\n",
        "\n",
        "\n",
        "def augment_and_mix(image, severity=3, width=3, depth=-1, alpha=1.):\n",
        "  \"\"\"Perform AugMix augmentations and compute mixture.\n",
        "\n",
        "  Args:\n",
        "    image: Raw input image as float32 np.ndarray of shape (h, w, c)\n",
        "    severity: Severity of underlying augmentation operators (between 1 to 10).\n",
        "    width: Width of augmentation chain\n",
        "    depth: Depth of augmentation chain. -1 enables stochastic depth uniformly\n",
        "      from [1, 3]\n",
        "    alpha: Probability coefficient for Beta and Dirichlet distributions.\n",
        "\n",
        "  Returns:\n",
        "    mixed: Augmented and mixed image.\n",
        "  \"\"\"\n",
        "  ws = np.float32(\n",
        "      np.random.dirichlet([alpha] * width))\n",
        "  m = np.float32(np.random.beta(alpha, alpha))\n",
        "\n",
        "  mix = np.zeros_like(image)\n",
        "  for i in range(width):\n",
        "    image_aug = image.copy()\n",
        "    d = depth if depth > 0 else np.random.randint(1, 4)\n",
        "    for _ in range(d):\n",
        "      op = np.random.choice(augmentations)\n",
        "      image_aug = apply_op(image_aug, op, severity)\n",
        "    # Preprocessing commutes since all coefficients are convex\n",
        "    #mix += ws[i] * normalize(image_aug)\n",
        "    mix += ws[i] * (np.expand_dims(image_aug, axis=2))\n",
        "\n",
        "  mixed = (1 - m) *  (image) + m * mix\n",
        "  return mixed\n",
        "\n",
        "\n",
        "def augmix_augment(data, doaug = True):\n",
        "  res = []\n",
        "  for i in data:\n",
        "    if doaug:\n",
        "      res.append(torch.Tensor(gen_colored(augment_and_mix(i.numpy()))[0].transpose(2,0,1)))\n",
        "    else:\n",
        "      res.append(torch.Tensor(gen_colored(i)[0].transpose(2,0,1)))\n",
        "  return(torch.stack(res))\n",
        "\n"
      ],
      "metadata": {
        "id": "8Hrwynn_9T81"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Copyright 2019 Google LLC\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "# ==============================================================================\n",
        "\"\"\"Base augmentations operators.\"\"\"\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image, ImageOps, ImageEnhance\n",
        "\n",
        "# ImageNet code should change this value\n",
        "IMAGE_SIZE = 28\n",
        "\n",
        "\n",
        "def int_parameter(level, maxval):\n",
        "  \"\"\"Helper function to scale `val` between 0 and maxval .\n",
        "\n",
        "  Args:\n",
        "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
        "    maxval: Maximum value that the operation can have. This will be scaled to\n",
        "      level/PARAMETER_MAX.\n",
        "\n",
        "  Returns:\n",
        "    An int that results from scaling `maxval` according to `level`.\n",
        "  \"\"\"\n",
        "  return int(level * maxval / 10)\n",
        "\n",
        "\n",
        "def float_parameter(level, maxval):\n",
        "  \"\"\"Helper function to scale `val` between 0 and maxval.\n",
        "\n",
        "  Args:\n",
        "    level: Level of the operation that will be between [0, `PARAMETER_MAX`].\n",
        "    maxval: Maximum value that the operation can have. This will be scaled to\n",
        "      level/PARAMETER_MAX.\n",
        "\n",
        "  Returns:\n",
        "    A float that results from scaling `maxval` according to `level`.\n",
        "  \"\"\"\n",
        "  return float(level) * maxval / 10.\n",
        "\n",
        "\n",
        "def sample_level(n):\n",
        "  return np.random.uniform(low=0.1, high=n)\n",
        "\n",
        "\n",
        "def autocontrast(pil_img, _):\n",
        "  return ImageOps.autocontrast(pil_img)\n",
        "\n",
        "\n",
        "def equalize(pil_img, _):\n",
        "  return ImageOps.equalize(pil_img)\n",
        "\n",
        "\n",
        "def posterize(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), 4)\n",
        "  return ImageOps.posterize(pil_img, 4 - level)\n",
        "\n",
        "\n",
        "def rotate(pil_img, level):\n",
        "  degrees = int_parameter(sample_level(level), 30)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    degrees = -degrees\n",
        "  return pil_img.rotate(degrees, resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def solarize(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), 256)\n",
        "  return ImageOps.solarize(pil_img, 256 - level)\n",
        "\n",
        "\n",
        "def shear_x(pil_img, level):\n",
        "  level = float_parameter(sample_level(level), 0.3)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, level, 0, 0, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def shear_y(pil_img, level):\n",
        "  level = float_parameter(sample_level(level), 0.3)\n",
        "  if np.random.uniform() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, 0, 0, level, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def translate_x(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n",
        "  if np.random.random() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, 0, level, 0, 1, 0),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "def translate_y(pil_img, level):\n",
        "  level = int_parameter(sample_level(level), IMAGE_SIZE / 3)\n",
        "  if np.random.random() > 0.5:\n",
        "    level = -level\n",
        "  return pil_img.transform((IMAGE_SIZE, IMAGE_SIZE),\n",
        "                           Image.AFFINE, (1, 0, 0, 0, 1, level),\n",
        "                           resample=Image.BILINEAR)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def color(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Color(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def contrast(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Contrast(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def brightness(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Brightness(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "# operation that overlaps with ImageNet-C's test set\n",
        "def sharpness(pil_img, level):\n",
        "    level = float_parameter(sample_level(level), 1.8) + 0.1\n",
        "    return ImageEnhance.Sharpness(pil_img).enhance(level)\n",
        "\n",
        "\n",
        "augmentations = [\n",
        "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
        "    translate_x, translate_y\n",
        "]\n",
        "\n",
        "augmentations_all = [\n",
        "    autocontrast, equalize, posterize, rotate, solarize, shear_x, shear_y,\n",
        "    translate_x, translate_y, color, contrast, brightness, sharpness\n",
        "]"
      ],
      "metadata": {
        "id": "Wfsi9tbf9T6M"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}