{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1c0sXzCAWKs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.models as models\n",
        "\n",
        "# Load the pre-trained ResNet-18 model\n",
        "model = models.resnet18(pretrained=True)\n",
        "# Freeze all the pre-trained layers\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "num_classes = 10 # replace with the number of classes in your dataset\n",
        "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tarfile\n",
        "from torchvision.datasets import CIFAR10\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Set the root directory for your custom dataset\n",
        "custom_dataset_root = \"./\"\n",
        "\n",
        "# Download and extract CIFAR-10 dataset\n",
        "cifar10_train = CIFAR10(root=custom_dataset_root, train=True, download=True, transform=transforms.ToTensor())\n",
        "cifar10_test = CIFAR10(root=custom_dataset_root, train=False, download=True, transform=transforms.ToTensor())\n",
        "\n",
        "\n",
        "\n",
        "# Create custom dataset directory structure\n",
        "train_dir = os.path.join(custom_dataset_root, os.path.join(\"cifar_10\", \"train\"))\n",
        "val_dir = os.path.join(custom_dataset_root, os.path.join(\"cifar_10\", \"val\"))\n",
        "\n",
        "# Create subdirectories for each class in train and val\n",
        "for i in range(10):\n",
        "    class_name = cifar10_train.classes[i]\n",
        "    os.makedirs(os.path.join(train_dir, class_name), exist_ok=True)\n",
        "    os.makedirs(os.path.join(val_dir, class_name), exist_ok=True)\n",
        "\n",
        "# Move images to the appropriate folders\n",
        "for i in range(len(cifar10_train)):\n",
        "    image, label = cifar10_train[i]\n",
        "    class_name = cifar10_train.classes[label]\n",
        "    folder_path = os.path.join(train_dir, class_name)\n",
        "\n",
        "    image_path = os.path.join(folder_path, f\"{i}.png\")\n",
        "    transforms.ToPILImage()(image).save(image_path)\n",
        "\n",
        "for i in range(len(cifar10_test)):\n",
        "    image, label = cifar10_test[i]\n",
        "    class_name = cifar10_test.classes[label]\n",
        "    folder_path = os.path.join(val_dir, class_name)\n",
        "\n",
        "    image_path = os.path.join(folder_path, f\"{i}.png\")\n",
        "    transforms.ToPILImage()(image).save(image_path)\n",
        "\n"
      ],
      "metadata": {
        "id": "dmLn1m4dAW95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision.transforms import transforms\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "# Define the transformations to apply to the images\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Load the train and validation datasets\n",
        "train_dataset = ImageFolder('./cifar_10/train', transform=transform)\n",
        "val_dataset = ImageFolder('./cifar_10/val', transform=transform)\n",
        "\n",
        "# Create data loaders for the train and validation datasets\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n"
      ],
      "metadata": {
        "id": "L_UWugsBAXA5"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_loader, val_loader, criterion, optimizer, num_epochs):\n",
        "    # Train the model for the specified number of epochs\n",
        "    for epoch in range(num_epochs):\n",
        "        # Set the model to train mode\n",
        "        model.train()\n",
        "\n",
        "        # Initialize the running loss and accuracy\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over the batches of the train loader\n",
        "        for inputs, labels in train_loader:\n",
        "            # Move the inputs and labels to the device\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Zero the optimizer gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            loss = criterion(outputs, labels)\n",
        "\n",
        "            # Backward pass and optimizer step\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Update the running loss and accuracy\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # Calculate the train loss and accuracy\n",
        "        train_loss = running_loss / len(train_dataset)\n",
        "        train_acc = running_corrects.double() / len(train_dataset)\n",
        "\n",
        "        # Set the model to evaluation mode\n",
        "        model.eval()\n",
        "\n",
        "        # Initialize the running loss and accuracy\n",
        "        running_loss = 0.0\n",
        "        running_corrects = 0\n",
        "\n",
        "        # Iterate over the batches of the validation loader\n",
        "        with torch.no_grad():\n",
        "            for inputs, labels in val_loader:\n",
        "                # Move the inputs and labels to the device\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # Forward pass\n",
        "                outputs = model(inputs)\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                # Update the running loss and accuracy\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "        # Calculate the validation loss and accuracy\n",
        "        val_loss = running_loss / len(val_dataset)\n",
        "        val_acc = running_corrects.double() / len(val_dataset)\n",
        "\n",
        "        # Print the epoch results\n",
        "    print('Epoch [{}/{}], train loss: {:.4f}, train acc: {:.4f}, val loss: {:.4f}, val acc: {:.4f}'\n",
        "              .format(epoch+1, num_epochs, train_loss, train_acc, val_loss, val_acc))\n"
      ],
      "metadata": {
        "id": "2q8IVDeRAXJQ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set the device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model.to(device)\n",
        "# Define the loss function and optimizer\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# Unfreeze all the layers and fine-tune the entire network for a few more epochs\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = True\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "train(model, train_loader, val_loader, criterion, optimizer, num_epochs=20)\n",
        "save_path = './resnet18_weights.pth'\n",
        "\n",
        "# Save the model weights\n",
        "torch.save(model.state_dict(), save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqz1hFB9MRC3",
        "outputId": "6a71f945-f01b-45d3-c1f8-5cf1c0981852"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [20/20], train loss: 0.0472, train acc: 0.9836, val loss: 0.8246, val acc: 0.8271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "deer_images = []\n",
        "cat_images = []\n",
        "\n",
        "# Select 5 deer images\n",
        "deer_indices = [i for i, label in enumerate(cifar10_test.targets) if label == 4][:5]\n",
        "deer_images = [(cifar10_test[i][0], 4) for i in deer_indices]  # 0 represents the label for deer\n",
        "\n",
        "# Select 300 cat images for now and will filter it down to 100 during poison image calculation\n",
        "cat_indices = [i for i, label in enumerate(cifar10_test.targets) if label == 3][:300]\n",
        "cat_images = [(cifar10_test[i][0], 3) for i in cat_indices]  # 1 represents the label for cat\n"
      ],
      "metadata": {
        "id": "rIjkfL2OVqmS"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def adam_one_step(model, m, v, t, currentImage, featRepTarget, learning_rate,\n",
        "                  beta_1=0.9, beta_2=0.999, eps=1e-8) -> torch.Tensor:\n",
        "    \"\"\"one step adam optimization\"\"\"\n",
        "    t += 1\n",
        "    currentImage = currentImage.detach() # disconnect image from the current autograd graph\n",
        "    currentImage.requires_grad_()\n",
        "\n",
        "    with torch.enable_grad():\n",
        "        logits = model(currentImage)\n",
        "        target_logits = model(featRepTarget)\n",
        "        loss = torch.norm(logits - target_logits)\n",
        "\n",
        "    grad_t = torch.autograd.grad(loss, [currentImage])[0]\n",
        "    m = beta_1 * m + (1-beta_1)*grad_t\n",
        "    v = beta_2 * v + (1-beta_2)*grad_t**2\n",
        "    m_hat = m/(1-beta_1**t)\n",
        "    v_hat = v/(1-beta_2**t)\n",
        "    with torch.no_grad():\n",
        "        currentImage -= learning_rate*m_hat/(torch.sqrt(v_hat)+eps)\n",
        "    return currentImage, m, v, t\n",
        "\n",
        "def forward_step(model, img: torch.Tensor, target_image: torch.Tensor,\n",
        "                 lr: float, target_logits) -> torch.Tensor:\n",
        "    \"\"\"helper function performing the forward step\"\"\"\n",
        "    img = img.detach() # disconnect image from the current autograd graph\n",
        "    img.requires_grad = True\n",
        "\n",
        "    logits = model(img)\n",
        "    loss = torch.norm(logits - target_logits)\n",
        "    model.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    img_grad = img.grad.data\n",
        "    perturbed_img = img - lr*img_grad\n",
        "    return perturbed_img\n",
        "\n",
        "def backward_step(img: torch.Tensor, base_img: torch.Tensor, lr: float, beta: float) -> torch.Tensor:\n",
        "    \"\"\"helper function to perform the backward step\"\"\"\n",
        "    perturbed_img = (img + lr*beta*base_img) / (1 + beta*lr)\n",
        "    perturbed_img = torch.clamp(perturbed_img, 0, 1) # to avoid clipping\n",
        "\n",
        "    return perturbed_img"
      ],
      "metadata": {
        "id": "fE06Gg4EhzzQ"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import copy\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def craft_clabel_poisons(model, target, bases, n_iter, lr, beta ,device):\n",
        "\n",
        "    print(\"[ Initialize.. ]\")\n",
        "    # create a global variable and assign the device which should be used\n",
        "\n",
        "    poisoned_images = torch.zeros((100, 3, 32,32))\n",
        "    poisoned_labels = torch.zeros((100))\n",
        "\n",
        "    target_image = target[0]\n",
        "    target_image_class = target[1]\n",
        "    target_image = torch.unsqueeze(target_image, axis = 0)\n",
        "\n",
        "    # calculate the beta\n",
        "    img_shape = np.squeeze(target_image).shape\n",
        "    #beta = 0.25 * (2048 / float(img_shape[0] * img_shape[1] * img_shape[2]))**2\n",
        "    #print(\"beta = {}\".format(beta))\n",
        "\n",
        "    # iterate over the whole test dataset and create a perturbed version of one (or N)\n",
        "    # new_class (the class as which the chosen image should be misclassified as) image.\n",
        "    adam = False\n",
        "    current_pertube_count = 0\n",
        "    for idx, (input, target_cls) in enumerate(bases):\n",
        "      if(current_pertube_count < 100):\n",
        "            difference = 100 # difference between base and target in feature space, will be updated\n",
        "            base_image, target_image = input.to(device), target_image.to(device)\n",
        "            base_image = torch.unsqueeze(base_image, axis = 0)\n",
        "\n",
        "            old_image = base_image\n",
        "\n",
        "            # Initializations\n",
        "            num_m = 40\n",
        "            last_m_objs = []\n",
        "            decay_coef = 0.5 #decay coeffiencet of learning rate\n",
        "            stopping_tol = 1e-10 #for the relative change\n",
        "            learning_rate = lr #iniital learning rate for optimization\n",
        "            rel_change_val = 1e5\n",
        "\n",
        "            target_feat_rep = model(target_image).detach()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            old_feat_rep = model(base_image).detach() #also known as the old image\n",
        "            old_obj = torch.linalg.norm(old_feat_rep - target_feat_rep) + \\\n",
        "                      beta*torch.linalg.norm(old_image - base_image)\n",
        "            last_m_objs.append(old_obj)\n",
        "\n",
        "            # perform the attack as described in the paper to optimize\n",
        "            # || f(x)-f(t) ||^2 + beta * || x-b ||^2\n",
        "            for iteration in range(n_iter):\n",
        "\n",
        "                if adam:\n",
        "                    new_image, m, v, t = adam_one_step(model, m, v, t, old_image, target_image,\n",
        "                                                       learning_rate)\n",
        "                else:\n",
        "                    new_image = forward_step(model, old_image, target_image,\n",
        "                                             learning_rate, copy.deepcopy(target_feat_rep))\n",
        "\n",
        "\n",
        "                new_image = backward_step(new_image, old_image, learning_rate, beta)\n",
        "\n",
        "                # check stopping condition:  compute relative change in image between iterations\n",
        "                rel_change_val = torch.linalg.norm(new_image-old_image)/torch.linalg.norm(new_image)\n",
        "\n",
        "                if (rel_change_val < stopping_tol) :\n",
        "                    print(\"! reached the object threshold -> stopping optimization !\")\n",
        "                    break\n",
        "\n",
        "                # compute new objective value\n",
        "                new_feat_rep = model(new_image).detach()\n",
        "                new_obj = torch.linalg.norm(new_feat_rep - target_feat_rep) + \\\n",
        "                          beta*torch.linalg.norm(new_image - base_image)\n",
        "\n",
        "                #find the mean of the last M iterations\n",
        "                avg_of_last_m = sum(last_m_objs)/float(min(num_m, iteration+1))\n",
        "                # If the objective went up, then learning rate is too big.\n",
        "                # Chop it, and throw out the latest iteration\n",
        "                if new_obj >= avg_of_last_m and (iteration % num_m/2 == 0):\n",
        "                    learning_rate *= decay_coef\n",
        "                    new_image = old_image\n",
        "                else:\n",
        "                    old_image = new_image\n",
        "                    old_obj = new_obj\n",
        "                    old_feat_rep = new_feat_rep\n",
        "\n",
        "                if iteration < num_m-1:\n",
        "                    last_m_objs.append(new_obj)\n",
        "                else:\n",
        "                    #first remove the oldest obj then append the new obj\n",
        "                    del last_m_objs[0]\n",
        "                    last_m_objs.append(new_obj)\n",
        "\n",
        "                # yes that's correct. The following lines will never be reached, exactly\n",
        "                # like in the original code. But adam optimization makes everything worse anyway..\n",
        "                if iteration > n_iter:\n",
        "                    m = 0.\n",
        "                    v = 0.\n",
        "                    t = 0\n",
        "                    adam = True\n",
        "\n",
        "                difference = torch.linalg.norm(old_feat_rep - target_feat_rep)\n",
        "\n",
        "            if difference < 3.5:\n",
        "                poisoned_images[current_pertube_count] = old_image # old_image is overwritten\n",
        "                poisoned_labels[current_pertube_count] = target_cls\n",
        "                current_pertube_count += 1\n",
        "\n",
        "    return poisoned_images, poisoned_labels"
      ],
      "metadata": {
        "id": "qBTyCctLa5JO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note :- Contrary to the question, i have finetuned upto 5 epochs due to google colab timeout, and CPU takes hours to run, I had tried for 2 target images with 10 epochs and the result is more prominent , i.e the target class is misclassifed more times ,around twice than that of 5 epoch version (current one)\n",
        "\n",
        "Numbers / result in this form represents,\n",
        "k [1,5,10,25,50,100] ---  the no of poisoned image in dataset\n",
        "['F', 'F', 'F', 'F', 'F', 'F'] --- whether the target image is misclassified to the cat class\n",
        "[40, 36, 47, 44, 55, 46]  --  the no of missclassified image to the cat class"
      ],
      "metadata": {
        "id": "4u5wO6q5BleY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "    for name, param in model.named_parameters():\n",
        "        if not name.startswith('fc'):\n",
        "            param.requires_grad = False\n",
        "\n",
        "    num_successful_attacks = 0\n",
        "    num_total_attacks = 0\n",
        "    k =[1, 5, 10, 25, 50, 100]\n",
        "    for i in range(5):\n",
        "          missc = []\n",
        "          missc_targ = []\n",
        "          # create a pertubed dataset with the chosen target / poison classes\n",
        "          poisoned_data = craft_clabel_poisons(model, deer_images[i], cat_images, 100, 0.01,0.01 ,  device)\n",
        "          for j in k:\n",
        "            misclassified_count = 0\n",
        "            # Load the state dictionary into the model\n",
        "\n",
        "            for name, param in model.named_parameters():\n",
        "              if not name.startswith('fc'):\n",
        "                param.requires_grad = False\n",
        "\n",
        "            model.load_state_dict(torch.load('/content/resnet18_weights.pth'))\n",
        "\n",
        "            m = 900000\n",
        "            for l in range(j):\n",
        "              filename = f\"X_{m}.png\"\n",
        "              image_path = os.path.join(\"./cifar_10/train/cat/\", filename )\n",
        "              transforms.ToPILImage()(poisoned_data[0][l]).save(image_path)\n",
        "              m+=1\n",
        "            train_dataset = ImageFolder('./cifar_10/train', transform=transform)\n",
        "            val_dataset = ImageFolder('./cifar_10/val', transform=transform)\n",
        "            train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "            val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
        "            optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "            train(model, train_loader, val_loader, criterion, optimizer, num_epochs=5)\n",
        "\n",
        "\n",
        "\n",
        "            with torch.no_grad():\n",
        "              model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "              if(torch.argmax(model(deer_images[i][0].unsqueeze(axis = 0).to(device))) == 3):\n",
        "                missc_targ.append(\"T\")\n",
        "              else:\n",
        "                missc_targ.append(\"F\")\n",
        "\n",
        "              for inputs, labels in val_loader:\n",
        "                  # Move the inputs and labels to the device\n",
        "                  inputs = inputs.to(device)\n",
        "                  labels = labels.to(device)\n",
        "\n",
        "                  # Forward pass\n",
        "                  outputs = model(inputs)\n",
        "                  _, preds = torch.max(outputs, 1)\n",
        "\n",
        "                  # Count misclassifications where original class is 3 (cat) and predicted class is 4 (deer)\n",
        "                  misclassified_count += torch.sum((labels == 4) & (preds == 3)).item()\n",
        "            missc.append(misclassified_count)\n",
        "\n",
        "          directory_path = \"/content/cifar_10/train/cat/\"\n",
        "\n",
        "          # Iterate over files in the directory\n",
        "          for filename in os.listdir(directory_path):\n",
        "              # Check if the filename starts with 'X_'\n",
        "              if filename.startswith(\"X_\"):\n",
        "                  file_path = os.path.join(directory_path, filename)\n",
        "\n",
        "                  # Remove the file\n",
        "                  os.remove(file_path)\n",
        "\n",
        "\n",
        "          print(f\"for target(deer) image {i}\")\n",
        "          print(\"k [1,5,10,25,50,100]\")\n",
        "          print(missc_targ)\n",
        "          print(missc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlMHE9hoVq1s",
        "outputId": "265db4b6-dd77-4b57-dc8a-e56693bcaca3"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ Initialize.. ]\n",
            "Epoch [5/5], train loss: 0.0321, train acc: 0.9894, val loss: 0.8119, val acc: 0.8327\n",
            "Epoch [5/5], train loss: 0.0343, train acc: 0.9893, val loss: 0.7974, val acc: 0.8332\n",
            "Epoch [5/5], train loss: 0.0347, train acc: 0.9888, val loss: 0.8002, val acc: 0.8320\n",
            "Epoch [5/5], train loss: 0.0384, train acc: 0.9874, val loss: 0.7988, val acc: 0.8332\n",
            "Epoch [5/5], train loss: 0.0401, train acc: 0.9866, val loss: 0.8312, val acc: 0.8293\n",
            "Epoch [5/5], train loss: 0.0404, train acc: 0.9862, val loss: 0.8019, val acc: 0.8312\n",
            "for target(deer) image 0\n",
            "k [1,5,10,25,50,100]\n",
            "['F', 'F', 'F', 'F', 'F', 'F']\n",
            "[40, 36, 47, 44, 55, 46]\n",
            "[ Initialize.. ]\n",
            "Epoch [5/5], train loss: 0.0347, train acc: 0.9882, val loss: 0.8247, val acc: 0.8311\n",
            "Epoch [5/5], train loss: 0.0341, train acc: 0.9883, val loss: 0.8017, val acc: 0.8330\n",
            "Epoch [5/5], train loss: 0.0362, train acc: 0.9881, val loss: 0.8121, val acc: 0.8330\n",
            "Epoch [5/5], train loss: 0.0370, train acc: 0.9878, val loss: 0.8147, val acc: 0.8317\n",
            "Epoch [5/5], train loss: 0.0384, train acc: 0.9872, val loss: 0.8675, val acc: 0.8290\n",
            "Epoch [5/5], train loss: 0.0373, train acc: 0.9873, val loss: 0.8024, val acc: 0.8304\n",
            "for target(deer) image 1\n",
            "k [1,5,10,25,50,100]\n",
            "['F', 'F', 'F', 'F', 'T', 'T']\n",
            "[37, 28, 37, 41, 45, 42]\n",
            "[ Initialize.. ]\n",
            "Epoch [5/5], train loss: 0.0328, train acc: 0.9893, val loss: 0.8103, val acc: 0.8326\n",
            "Epoch [5/5], train loss: 0.0348, train acc: 0.9887, val loss: 0.8203, val acc: 0.8336\n",
            "Epoch [5/5], train loss: 0.0371, train acc: 0.9876, val loss: 0.8073, val acc: 0.8331\n",
            "Epoch [5/5], train loss: 0.0361, train acc: 0.9880, val loss: 0.7972, val acc: 0.8325\n",
            "Epoch [5/5], train loss: 0.0374, train acc: 0.9870, val loss: 0.8744, val acc: 0.8284\n",
            "Epoch [5/5], train loss: 0.0367, train acc: 0.9877, val loss: 0.7968, val acc: 0.8332\n",
            "for target(deer) image 2\n",
            "k [1,5,10,25,50,100]\n",
            "['F', 'F', 'F', 'F', 'F', 'T']\n",
            "[32, 29, 37, 41, 48, 38]\n",
            "[ Initialize.. ]\n",
            "Epoch [5/5], train loss: 0.0330, train acc: 0.9891, val loss: 0.8246, val acc: 0.8326\n",
            "Epoch [5/5], train loss: 0.0340, train acc: 0.9889, val loss: 0.8184, val acc: 0.8304\n",
            "Epoch [5/5], train loss: 0.0343, train acc: 0.9882, val loss: 0.8186, val acc: 0.8323\n",
            "Epoch [5/5], train loss: 0.0359, train acc: 0.9880, val loss: 0.8066, val acc: 0.8320\n",
            "Epoch [5/5], train loss: 0.0384, train acc: 0.9868, val loss: 0.8403, val acc: 0.8282\n",
            "Epoch [5/5], train loss: 0.0363, train acc: 0.9874, val loss: 0.8049, val acc: 0.8337\n",
            "for target(deer) image 3\n",
            "k [1,5,10,25,50,100]\n",
            "['F', 'F', 'F', 'F', 'F', 'T']\n",
            "[42, 29, 24, 45, 48, 48]\n",
            "[ Initialize.. ]\n",
            "Epoch [5/5], train loss: 0.0355, train acc: 0.9879, val loss: 0.8046, val acc: 0.8324\n",
            "Epoch [5/5], train loss: 0.0342, train acc: 0.9890, val loss: 0.8208, val acc: 0.8326\n",
            "Epoch [5/5], train loss: 0.0356, train acc: 0.9884, val loss: 0.8056, val acc: 0.8342\n",
            "Epoch [5/5], train loss: 0.0378, train acc: 0.9877, val loss: 0.8012, val acc: 0.8302\n",
            "Epoch [5/5], train loss: 0.0405, train acc: 0.9868, val loss: 0.8642, val acc: 0.8267\n",
            "Epoch [5/5], train loss: 0.0405, train acc: 0.9862, val loss: 0.7873, val acc: 0.8321\n",
            "for target(deer) image 4\n",
            "k [1,5,10,25,50,100]\n",
            "['F', 'F', 'F', 'F', 'F', 'F']\n",
            "[39, 33, 42, 58, 68, 46]\n"
          ]
        }
      ]
    }
  ]
}